
# Neural Networks and Machine Learning Exploration

This repository contains a Jupyter Notebook that explores neural networks, their implementation, and optimization techniques in machine learning. The project highlights the versatility of neural networks for modeling linear and non-linear data relationships, while also comparing their performance with simpler models such as decision trees.

---

## Features

1. **Introduction to Tensors**:
   - Explains tensors, their role as the backbone of neural networks, and how they facilitate efficient computations in machine learning.
   - Example usage of Python to represent tensors as multidimensional arrays.

2. **Neural Network Architecture**:
   - Covers the structure of a neural network (input, hidden, and output layers).
   - Includes details on hyperparameter tuning for optimal performance.

3. **Training Process**:
   - Demonstrates the use of gradient descent and loss functions to iteratively improve the model.
   - Includes training loops to show how the model's performance evolves over epochs.

4. **Visualization**:
   - Provides a histogram comparing the model's predictions and true labels, offering insights into the model's accuracy.

5. **Comparison of Models**:
   - Highlights the performance of neural networks versus decision trees.
   - Discusses the computational challenges and potential for neural networks to improve with further tuning.

---

## Requirements

To run this notebook, you will need:

- Python 3.8 or later
- Libraries:
  - NumPy
  - Matplotlib
  - PyTorch (or TensorFlow for adaptation)
  - Scikit-learn (for decision tree comparisons)

---


## Results

- Achieved an **F1 Score** of ~0.87 and an **Accuracy** of ~0.97 using the neural network model.
- Decision tree model provided superior results with an **F1 Score** and **Accuracy** close to 0.99.
- Visualizations highlight model predictions and areas for improvement.

---

## Future Work

- Further hyperparameter optimization for neural networks.
- Implementation of additional models for comparison, such as Random Forests or Gradient Boosting.
- Exploration of advanced neural network architectures like CNNs or RNNs.

---

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## Contributing

Contributions are welcome! Feel free to open issues or submit pull requests with improvements, bug fixes, or additional features.

---

## Acknowledgments

- This project was developed as part of an academic exercise in machine learning.
- Thanks to open-source libraries and documentation that supported this work.

